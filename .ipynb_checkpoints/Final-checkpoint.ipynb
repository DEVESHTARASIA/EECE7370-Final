{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b30d0868",
   "metadata": {},
   "source": [
    "# Importing \n",
    "Importing necessary libraries and loading the PreTrained MobileNetV2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ca9bf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f58757",
   "metadata": {},
   "source": [
    "# Custom loss functions\n",
    "\n",
    "Following the paper's description of loss function as wrong_NLL()\n",
    "Proposing our own description of loss function as NLL()\n",
    "\n",
    "The first 140 elements are the flattened landmarks and the last 70 values correspond to the uncertainities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5551ab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrong_NLL(output, # Tensor of shape [b_sze, 210 (70 landmarks by 3)]\n",
    "             target, # Tensor of shape [b_sze,140]\n",
    "             ):\n",
    "\n",
    "    \"\"\"\n",
    "    The output structure is essentially a 2d tensor of of shape [b_sze, 210 (70 landmarks by 3)].\n",
    "    Each instance (210 length vector) are a sequence of (x,y) locations for 70 landmarks which makes the first 136 elements. The rest 70 elements of the vector \n",
    "    are the standard deviation of the probabilistic regression.\n",
    "    \"\"\"\n",
    "    b_sze = output.size()[0]\n",
    "\n",
    "    crit = nn.MSELoss(reduction='none')\n",
    "    loss = crit(output[:,:140].view(b_sze,2,-1), target.view(b_sze,2,-1))\n",
    "    loss = torch.sum(loss,dim=1)\n",
    "    loss = loss/(2*output[:,140:]**2)\n",
    "    \n",
    "    return torch.sum(torch.log(output[:,140:]**2)) + torch.sum(loss)\n",
    "\n",
    "\n",
    "def NLL(output, # Tensor of shape [b_sze, 210 (70 landmarks by 3)]\n",
    "        target, # Tensor of shape [b_sze,140]\n",
    "             ):\n",
    "\n",
    "    \"\"\"\n",
    "    The output structure is essentially a 2d tensor of of shape [b_sze, 210 (70 landmarks by 3)].\n",
    "    Each instance (210 length vector) are a sequence of (x,y) locations for 70 landmarks which makes the first 140 elements. The rest 70 elements of the vector \n",
    "    are the standard deviation of the probabilistic regression.\n",
    "    \"\"\"\n",
    "    \n",
    "    b_sze = output.size()[0]\n",
    "\n",
    "    crit = nn.MSELoss(reduction='none')\n",
    "    loss = crit(output[:,:140].view(b_sze,2,-1), target.view(b_sze,2,-1))\n",
    "    loss = torch.sum(loss,dim=1)\n",
    "    loss = loss/(2*output[:,140:]**2)\n",
    "    \n",
    "    return torch.sum(0.5*(torch.log(output[:,140:]**2))) + torch.sum(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d632c8",
   "metadata": {},
   "source": [
    "# Custom Dataset Class\n",
    "\n",
    "The class read root directory location and generates normalised values of images and landmarks\n",
    "\n",
    "The image is mapped to range [0,1] after being resized to 224x224\n",
    "\n",
    "The landmarks is mapped to range [-1,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c49384a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceLandmarksDataset(Dataset):\n",
    "    def __init__(self,root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.len = 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        files = os.listdir(self.root_dir)\n",
    "        self.len = int(len(files)/3)\n",
    "        return self.len\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        item_name = str(idx)\n",
    "        item_name = item_name.zfill(6)\n",
    "        \n",
    "        img_name = self.root_dir+item_name+\".png\"\n",
    "        \n",
    "        ldmks_file_name = self.root_dir+item_name+\"_ldmks.txt\"\n",
    "        with open(ldmks_file_name) as f:\n",
    "            landmarks = np.loadtxt(f)\n",
    "        landmarks = torch.tensor(landmarks)\n",
    "        landmarks = torch.reshape(landmarks,(140,))\n",
    "        landmarks = landmarks/256 - 1\n",
    "        \n",
    "        img = Image.open(img_name)\n",
    "        resizer = transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor()])\n",
    "        img = resizer(img)\n",
    "        \n",
    "        sample = {\"image\":img,\"landmarks\":landmarks}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492af1f8",
   "metadata": {},
   "source": [
    "# Dataloading\n",
    "\n",
    "Created a split of 90% to 10% of training and test with a batch size of 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe9afaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FaceLandmarksDataset(\"/workspace/EECE7370-Final/Dataset/\")\n",
    "training_data,testing_data = random_split(dataset,[900,100]) \n",
    "train_dataloader = DataLoader(training_data,batch_size=8,shuffle=True)\n",
    "test_dataloader = DataLoader(testing_data,batch_size=8,shuffle=True)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad32ea6",
   "metadata": {},
   "source": [
    "# Facial Landmark Detector Model\n",
    "\n",
    "Used pretrained weights of MobileNetV2 CNN feature extractor and converting the final layer to output 210 values(70 x and y coordinates and 70 uncertainities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a799814",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = model.features\n",
    "class Mobile_LandmarkDetector(nn.Module):\n",
    "    def __init__(self,feature_extractor_model):\n",
    "            super().__init__()\n",
    "            self.feature_extractor_model = feature_extractor_model\n",
    "            self.regressor_op = nn.Sequential(nn.Dropout(p=0.5),nn.Linear(in_features=1280,out_features=210,bias=True))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.feature_extractor_model(x)\n",
    "        x = nn.functional.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.regressor_op(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "our_model = Mobile_LandmarkDetector(feature_extractor_model=feature_extractor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe1375b",
   "metadata": {},
   "source": [
    "# Training and Optimization\n",
    "\n",
    "Will be only training the last layer and freeze the feature extractor layers\n",
    "\n",
    "With AdamW optimizer and 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45026f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Training loss is 1.805535912513733, validation loss is 0.05068821787834168\n",
      "epoch 1\n",
      "Training loss is 0.9869672656059265, validation loss is 0.04473572731018066\n",
      "epoch 2\n",
      "Training loss is 0.9664744734764099, validation loss is 0.03702181696891785\n",
      "epoch 3\n",
      "Training loss is 1.0021789073944092, validation loss is 0.03585353374481201\n",
      "epoch 4\n",
      "Training loss is 1.0111545324325562, validation loss is 0.03808571100234985\n",
      "epoch 5\n",
      "Training loss is 0.9801980257034302, validation loss is 0.047182943820953366\n",
      "epoch 6\n",
      "Training loss is 1.018977165222168, validation loss is 0.04826064825057983\n",
      "epoch 7\n",
      "Training loss is 1.0246772766113281, validation loss is 0.04417385578155517\n",
      "epoch 8\n",
      "Training loss is 1.0144410133361816, validation loss is 0.04389870882034302\n",
      "epoch 9\n",
      "Training loss is 0.947803258895874, validation loss is 0.038990523219108585\n",
      "epoch 10\n",
      "Training loss is 1.0743993520736694, validation loss is 0.03848869919776916\n",
      "epoch 11\n",
      "Training loss is 1.05697500705719, validation loss is 0.03758422076702118\n",
      "epoch 12\n",
      "Training loss is 1.1032978296279907, validation loss is 0.05074185013771057\n",
      "epoch 13\n",
      "Training loss is 1.1299538612365723, validation loss is 0.09188151121139526\n",
      "epoch 14\n",
      "Training loss is 1.2890655994415283, validation loss is 0.09648285150527953\n",
      "epoch 15\n",
      "Training loss is 1.142561435699463, validation loss is 0.09764816761016845\n",
      "epoch 16\n",
      "Training loss is 1.173458218574524, validation loss is 0.09514110088348389\n",
      "epoch 17\n",
      "Training loss is 1.1456265449523926, validation loss is 0.10062736511230469\n",
      "epoch 18\n",
      "Training loss is 1.1650246381759644, validation loss is 0.09292638301849365\n",
      "epoch 19\n",
      "Training loss is 1.142792820930481, validation loss is 0.09644261598587037\n",
      "epoch 20\n",
      "Training loss is 1.154465913772583, validation loss is 0.09103573083877564\n",
      "epoch 21\n",
      "Training loss is 1.134811282157898, validation loss is 0.0809180748462677\n",
      "epoch 22\n",
      "Training loss is 1.2438701391220093, validation loss is 0.10479193449020385\n",
      "epoch 23\n",
      "Training loss is 1.207395315170288, validation loss is 0.11445545196533204\n",
      "epoch 24\n",
      "Training loss is 1.2061259746551514, validation loss is 0.10658174753189087\n",
      "epoch 25\n",
      "Training loss is 1.176387071609497, validation loss is 0.10442505836486816\n",
      "epoch 26\n",
      "Training loss is 1.2643885612487793, validation loss is 0.12613470554351808\n",
      "epoch 27\n",
      "Training loss is 1.238784909248352, validation loss is 0.12282350540161133\n",
      "epoch 28\n",
      "Training loss is 1.232155203819275, validation loss is 0.11645627021789551\n",
      "epoch 29\n",
      "Training loss is 1.255271553993225, validation loss is 0.14390172958374023\n",
      "epoch 30\n",
      "Training loss is 1.3149535655975342, validation loss is 0.15230444192886353\n",
      "epoch 31\n",
      "Training loss is 1.309801697731018, validation loss is 0.1343336296081543\n",
      "epoch 32\n",
      "Training loss is 1.3227020502090454, validation loss is 0.12894325256347655\n",
      "epoch 33\n",
      "Training loss is 1.3404558897018433, validation loss is 0.14201172351837157\n",
      "epoch 34\n",
      "Training loss is 1.3628991842269897, validation loss is 0.13868515491485595\n",
      "epoch 35\n",
      "Training loss is 1.4029409885406494, validation loss is 0.1481528401374817\n",
      "epoch 36\n",
      "Training loss is 1.4087378978729248, validation loss is 0.15098453998565675\n",
      "epoch 37\n",
      "Training loss is 1.4349881410598755, validation loss is 0.15037489652633668\n",
      "epoch 38\n",
      "Training loss is 1.423485279083252, validation loss is 0.14443642616271973\n",
      "epoch 39\n",
      "Training loss is 1.3730928897857666, validation loss is 0.12704752922058105\n",
      "epoch 40\n",
      "Training loss is 1.3873411417007446, validation loss is 0.12487298965454102\n",
      "epoch 41\n",
      "Training loss is 1.424615740776062, validation loss is 0.1354200768470764\n",
      "epoch 42\n",
      "Training loss is 1.376587986946106, validation loss is 0.1270434546470642\n",
      "epoch 43\n",
      "Training loss is 1.3655571937561035, validation loss is 0.11301162958145142\n",
      "epoch 44\n",
      "Training loss is 1.3497288227081299, validation loss is 0.10954857349395752\n",
      "epoch 45\n",
      "Training loss is 1.4241257905960083, validation loss is 0.12019872426986694\n",
      "epoch 46\n",
      "Training loss is 1.4625740051269531, validation loss is 0.1263464879989624\n",
      "epoch 47\n",
      "Training loss is 1.4023302793502808, validation loss is 0.12595421552658081\n",
      "epoch 48\n",
      "Training loss is 1.4084278345108032, validation loss is 0.11353553533554077\n",
      "epoch 49\n",
      "Training loss is 1.4119155406951904, validation loss is 0.10798834562301636\n",
      "epoch 50\n",
      "Training loss is 1.3915197849273682, validation loss is 0.11026453018188477\n",
      "epoch 51\n",
      "Training loss is 1.3724614381790161, validation loss is 0.10814787864685059\n",
      "epoch 52\n",
      "Training loss is 1.3759584426879883, validation loss is 0.10707735776901245\n",
      "epoch 53\n",
      "Training loss is 1.3823089599609375, validation loss is 0.09770503520965576\n",
      "epoch 54\n",
      "Training loss is 1.3889240026474, validation loss is 0.09506561517715455\n",
      "epoch 55\n",
      "Training loss is 1.3824236392974854, validation loss is 0.08437374472618103\n",
      "epoch 56\n",
      "Training loss is 1.3579574823379517, validation loss is 0.08940218210220337\n",
      "epoch 57\n",
      "Training loss is 1.3272415399551392, validation loss is 0.09277130365371704\n",
      "epoch 58\n",
      "Training loss is 1.3600531816482544, validation loss is 0.12578407049179077\n",
      "epoch 59\n",
      "Training loss is 1.376346468925476, validation loss is 0.13816887855529786\n",
      "epoch 60\n",
      "Training loss is 1.4046356678009033, validation loss is 0.19410983085632325\n",
      "epoch 61\n",
      "Training loss is 1.3845628499984741, validation loss is 0.1954423713684082\n",
      "epoch 62\n",
      "Training loss is 1.4145902395248413, validation loss is 0.192694354057312\n",
      "epoch 63\n",
      "Training loss is 2.345522403717041, validation loss is 0.22886765003204346\n",
      "epoch 64\n",
      "Training loss is 1.5010513067245483, validation loss is 0.20848191738128663\n",
      "epoch 65\n",
      "Training loss is 1.464238166809082, validation loss is 0.18587710380554198\n",
      "epoch 66\n",
      "Training loss is 1.4875800609588623, validation loss is 0.20307555675506592\n",
      "epoch 67\n",
      "Training loss is 5.774573802947998, validation loss is 0.18309707641601564\n",
      "epoch 68\n",
      "Training loss is 1.5033900737762451, validation loss is 0.22153748989105224\n",
      "epoch 69\n",
      "Training loss is 1.5017262697219849, validation loss is 0.21827879905700684\n",
      "epoch 70\n",
      "Training loss is 1.7164064645767212, validation loss is 0.20796123027801514\n",
      "epoch 71\n",
      "Training loss is 1.5731656551361084, validation loss is 0.28250202655792234\n",
      "epoch 72\n",
      "Training loss is 1.5396333932876587, validation loss is 0.27160143852233887\n",
      "epoch 73\n",
      "Training loss is 1.5580053329467773, validation loss is 0.2624962329864502\n",
      "epoch 74\n",
      "Training loss is 1.5601985454559326, validation loss is 0.2789409112930298\n",
      "epoch 75\n",
      "Training loss is 1.594765305519104, validation loss is 0.2676055812835693\n",
      "epoch 76\n",
      "Training loss is 1.7823008298873901, validation loss is 0.24978138446807863\n",
      "epoch 77\n",
      "Training loss is 1.587453842163086, validation loss is 0.2592215156555176\n",
      "epoch 78\n",
      "Training loss is 1.616246223449707, validation loss is 0.24499611854553222\n",
      "epoch 79\n",
      "Training loss is 1.607509970664978, validation loss is 0.23833078861236573\n",
      "epoch 80\n",
      "Training loss is 1.6105403900146484, validation loss is 0.22320769786834715\n",
      "epoch 81\n",
      "Training loss is 1.559995412826538, validation loss is 0.21046192646026612\n",
      "epoch 82\n",
      "Training loss is 1.5440834760665894, validation loss is 0.2020863437652588\n",
      "epoch 83\n",
      "Training loss is 1.5608218908309937, validation loss is 0.21006329536437987\n",
      "epoch 84\n",
      "Training loss is 1.5590217113494873, validation loss is 0.19670795917510986\n",
      "epoch 85\n",
      "Training loss is 1.5756756067276, validation loss is 0.19378237247467042\n",
      "epoch 86\n",
      "Training loss is 1.562261700630188, validation loss is 0.23033454418182372\n",
      "epoch 87\n",
      "Training loss is 1.5575019121170044, validation loss is 0.23871119499206542\n",
      "epoch 88\n",
      "Training loss is 1.5741935968399048, validation loss is 0.23878738403320313\n",
      "epoch 89\n",
      "Training loss is 1.5772649049758911, validation loss is 0.2189897584915161\n",
      "epoch 90\n",
      "Training loss is 1.5705622434616089, validation loss is 0.22676035404205322\n",
      "epoch 91\n",
      "Training loss is 1.5598567724227905, validation loss is 0.20879474639892578\n",
      "epoch 92\n",
      "Training loss is 1.5502314567565918, validation loss is 0.20932411193847655\n",
      "epoch 93\n",
      "Training loss is 1.55916428565979, validation loss is 0.20535576343536377\n",
      "epoch 94\n",
      "Training loss is 1.5521808862686157, validation loss is 0.24858180522918702\n",
      "epoch 95\n",
      "Training loss is 1.6308131217956543, validation loss is 0.24747597217559814\n",
      "epoch 96\n",
      "Training loss is 1.6106979846954346, validation loss is 0.23383912563323975\n",
      "epoch 97\n",
      "Training loss is 1.5491127967834473, validation loss is 0.2323476791381836\n",
      "epoch 98\n",
      "Training loss is 1.5721843242645264, validation loss is 0.23819807052612305\n",
      "epoch 99\n",
      "Training loss is 1.534744381904602, validation loss is 0.22502243518829346\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "our_model.to(device)\n",
    "for param in our_model.feature_extractor_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "optimizer = torch.optim.AdamW(our_model.regressor_op.parameters())\n",
    "mse = nn.MSELoss(reduction=\"mean\") #NME\n",
    "best_model_NLL = our_model\n",
    "best_loss = np.inf\n",
    "#Training\n",
    "for q in range(100):\n",
    "    our_model.train()\n",
    "    print(f\"epoch {q}\")\n",
    "    for i,(batch) in enumerate(train_dataloader):\n",
    "        ip,op = batch[\"image\"],batch[\"landmarks\"]\n",
    "        ip = ip.to(device)\n",
    "        op = op.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred_op = our_model(ip)\n",
    "        crit = nn.GaussianNLLLoss()\n",
    "        landmarks = pred_op[:,:140]\n",
    "        landmarks = torch.reshape(landmarks,(-1,70,2))\n",
    "        var = pred_op[:,140:]**2\n",
    "        op = torch.reshape(op,(-1,70,2))\n",
    "        loss = crit(landmarks,op,var)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        writer.add_scalar(\"Training Loss:\", loss, q)\n",
    "        \n",
    "    our_model.eval()    \n",
    "    with torch.no_grad():\n",
    "        tot_loss = 0\n",
    "        for i_val,(batch_val) in enumerate(test_dataloader):\n",
    "            ip_test,op_test = batch_val[\"image\"],batch_val[\"landmarks\"]\n",
    "            ip_test = ip_test.to(device)\n",
    "            op_test = op_test.float().to(device)\n",
    "            pred_op = our_model(ip_test)\n",
    "            #print(pred_op.shape)\n",
    "            #minie = torch.min(pred_op)\n",
    "            #maxie = torch.max(pred_op)\n",
    "            #pred_op = (pred_op-minie)/(maxie-minie)\n",
    "            #pred_op = pred_op*2 - 1\n",
    "            l = mse(pred_op[:,:140],op_test)\n",
    "            tot_loss += l.item()\n",
    "            \n",
    "        tot_loss = tot_loss/testing_data.__len__()\n",
    "        writer.add_scalar(\"Testing Loss\",tot_loss,q)\n",
    "        \n",
    "    if tot_loss < best_loss:\n",
    "        best_loss = tot_loss\n",
    "        best_model_NLL = our_model\n",
    "\n",
    "    print(f\"Training loss is {loss.item()}, validation loss is {tot_loss}\")\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba6d2a3",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5781a9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./Model/final_model.pt\"\n",
    "torch.save(best_model_NLL.state_dict(),path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
